{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nazarb/2025_levees_DL/blob/main/swin_unetr_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#"
      ],
      "metadata": {
        "id": "ZXnJgBVw7jVv"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Levee detection demo\n",
        "\n",
        "The file contains the demonstation of the Swin UNETR model for detection of the levees. The original model is run in the Docker enviroment, which published in the Git repository\n",
        "\n",
        "This versin of the model can predict the levees, run post-processing and save the results"
      ],
      "metadata": {
        "id": "v_rdaIDgHVkP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clone the repository"
      ],
      "metadata": {
        "id": "380fvCrWUBdp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/nazarb/2025_levees_DL.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qogb8pZp_Zyu",
        "outputId": "07c593ac-9589-47e0-f25f-a4148539ebc1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into '2025_levees_DL'...\n",
            "remote: Enumerating objects: 613, done.\u001b[K\n",
            "remote: Counting objects: 100% (279/279), done.\u001b[K\n",
            "remote: Compressing objects: 100% (217/217), done.\u001b[K\n",
            "remote: Total 613 (delta 145), reused 15 (delta 15), pack-reused 334 (from 2)\u001b[K\n",
            "Receiving objects: 100% (613/613), 1.15 MiB | 1.66 MiB/s, done.\n",
            "Resolving deltas: 100% (270/270), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set up path for further processing"
      ],
      "metadata": {
        "id": "14XsO2cPUG_q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "basepath = os.getcwd()\n",
        "print(basepath)\n",
        "# set other paths for quick navigation\n",
        "git_path = os.path.join(basepath, \"2025_levees_DL\")\n",
        "print(git_path)\n",
        "Swin_UNETR_path = os.path.join(git_path, \"Swin_UNETR\")\n",
        "print(Swin_UNETR_path)\n",
        "results_path = os.path.join(Swin_UNETR_path, \"results/Swin_UNETR/Aug\")\n",
        "os.makedirs(results_path, exist_ok=True)\n",
        "print(results_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IeNCwj4YCKoe",
        "outputId": "9fa580c4-d71c-4171-d712-e18d3090a588"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "/content/2025_levees_DL\n",
            "/content/2025_levees_DL/Swin_UNETR\n",
            "/content/2025_levees_DL/Swin_UNETR/results/Swin_UNETR/Aug\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install libraries"
      ],
      "metadata": {
        "id": "s7J256lDUNPh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --no-cache-dir monai==1.3.2\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xPR069_Y7CF-",
        "outputId": "5fefe8bb-5f49-4eac-918e-18264f9f927e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting monai==1.3.2\n",
            "  Downloading monai-1.3.2-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: torch>=1.9 in /usr/local/lib/python3.12/dist-packages (from monai==1.3.2) (2.8.0+cu126)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.12/dist-packages (from monai==1.3.2) (2.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.9->monai==1.3.2) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9->monai==1.3.2) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.9->monai==1.3.2) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9->monai==1.3.2) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.9->monai==1.3.2) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9->monai==1.3.2) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.9->monai==1.3.2) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9->monai==1.3.2) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9->monai==1.3.2) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9->monai==1.3.2) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9->monai==1.3.2) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9->monai==1.3.2) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9->monai==1.3.2) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9->monai==1.3.2) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9->monai==1.3.2) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9->monai==1.3.2) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9->monai==1.3.2) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9->monai==1.3.2) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9->monai==1.3.2) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9->monai==1.3.2) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9->monai==1.3.2) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9->monai==1.3.2) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.9->monai==1.3.2) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.9->monai==1.3.2) (3.0.3)\n",
            "Downloading monai-1.3.2-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: monai\n",
            "Successfully installed monai-1.3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt install megatools\n",
        "!pip install rasterio\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6XgwH_fCSsWj",
        "outputId": "456986d2-5bdc-4089-b2d5-6b7c914a962d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "megatools is already the newest version (1.10.3-1build1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 38 not upgraded.\n",
            "Requirement already satisfied: rasterio in /usr/local/lib/python3.12/dist-packages (1.4.3)\n",
            "Requirement already satisfied: affine in /usr/local/lib/python3.12/dist-packages (from rasterio) (2.4.0)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.12/dist-packages (from rasterio) (25.4.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from rasterio) (2025.10.5)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.12/dist-packages (from rasterio) (8.3.0)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.12/dist-packages (from rasterio) (0.7.2)\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.12/dist-packages (from rasterio) (2.0.2)\n",
            "Requirement already satisfied: click-plugins in /usr/local/lib/python3.12/dist-packages (from rasterio) (1.1.1.2)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from rasterio) (3.2.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import torch\n",
        "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "torch.cuda.is_available()\n",
        "torch.cuda.device_count()\n",
        "torch.cuda.current_device()\n",
        "torch.cuda.get_device_name(0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "jtL4rltonLEE",
        "outputId": "10f4cbf9-0614-45cd-f8ba-d7d3d5d58872"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tesla T4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download the data and the model\n",
        "\n",
        "The raster data used in this study is calculated with the provided Google Earth Engine code. The model is published in the Dane Badawcze UW repository (Published version: 2025-09-24):\n",
        "\n",
        "```\n",
        "Buławka, Nazarij; Orengo, Hector A.; Lumbreras Ruiz, Felipe; Berganzo-Besga, Iban; Gupta, Ekta, 2025, \"Traces of ancient irrigation in central Iraq detected using deep learning model\", https://doi.org/10.58132/MY8CCL, Dane Badawcze UW, V1\n",
        "```\n"
      ],
      "metadata": {
        "id": "WLqsU9YzURvA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import requests\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# Download data the raster calculated with provided Google Earth Engine code\n",
        "\n",
        "\n",
        "# MEGA file URL\n",
        "mega_url = \"https://mega.nz/file/E9gBCCjR#UCDklOgOVOwQ0hRAIy5pvAdX9Y-VLBQktDlsrj4R1Ms\"\n",
        "\n",
        "# Temporary download path (megadl saves the file with original name by default)\n",
        "download_dir = \"/content\"\n",
        "downloaded_file = os.path.join(download_dir, \"CFE_a_selected_L5_S2_S1_MSRM_PCA_GLO_N48.tif\")\n",
        "\n",
        "# Target directory\n",
        "target_dir1 = f'{Swin_UNETR_path}/data'\n",
        "os.makedirs(target_dir1, exist_ok=True)\n",
        "\n",
        "# Download file using megadl\n",
        "!megadl \"{mega_url}\" --path \"{download_dir}\"\n",
        "\n",
        "# Move the file to target directory (if needed rename)\n",
        "shutil.move(downloaded_file, os.path.join(target_dir1, \"CFE_a_selected_L5_S2_S1_MSRM_PCA_GLO_N48.tif\"))\n",
        "print(f\"File moved to: {target_dir1}\")\n",
        "\n",
        "image_path = os.path.join(target_dir1, \"CFE_a_selected_L5_S2_S1_MSRM_PCA_GLO_N48.tif\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fj5EBoxPEx0N",
        "outputId": "9786c7d4-7e49-4b25-cd43-ca05907cf9bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": []
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the model from the Dane Badawcze UW repository (Published version: 2025-09-24):\n",
        "## Buławka, Nazarij; Orengo, Hector A.; Lumbreras Ruiz, Felipe; Berganzo-Besga, Iban; Gupta, Ekta, 2025, \"Traces of ancient irrigation in central Iraq detected using deep learning model\", https://doi.org/10.58132/MY8CCL, Dane Badawcze UW, V1\n",
        "\n",
        "## URL of the file\n",
        "url = \"https://danebadawcze.uw.edu.pl/api/access/datafile/17759\"\n",
        "\n",
        "## Download location\n",
        "download_path = \"/content/Levees_SWINUNETR_48_best.pth\"\n",
        "\n",
        "## Target directory\n",
        "target_dir2 = f'{Swin_UNETR_path}/model/Swin_UNETR/Aug'\n",
        "os.makedirs(target_dir2, exist_ok=True)  # create dir if it doesn't exist\n",
        "\n",
        "## Download the file\n",
        "print(\"Downloading...\")\n",
        "response = requests.get(url, stream=True)\n",
        "with open(download_path, \"wb\") as f:\n",
        "    shutil.copyfileobj(response.raw, f)\n",
        "print(\"Download complete.\")\n",
        "\n",
        "3# Move to target directory\n",
        "final_path = os.path.join(target_dir2, \"Levees_SWINUNETR_48_best.pth\")\n",
        "shutil.move(download_path, final_path)\n",
        "print(f\"File moved to: {final_path}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hj_MooVYbQol",
        "outputId": "7f38361b-20fc-4489-cd97-c4502f991ede"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "Download complete.\n",
            "File moved to: /content/2025_levees_DL/Swin_UNETR/model/Swin_UNETR/Aug/Levees_SWINUNETR_48_best.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Predict\n",
        "\n",
        "Swin_UNETR_pth = os.path.join(target_dir2, \"Levees_SWINUNETR_48_best.pth\")\n",
        "print({Swin_UNETR_pth})\n",
        "data_path =  os.path.join(target_dir1, \"CFE_a_selected_L5_S2_S1_MSRM_PCA_GLO_N48.tif\")\n",
        "print(data_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VHz4Y6-tCndL",
        "outputId": "99687aae-f12a-4c85-abca-b4a316ca0853"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'/content/2025_levees_DL/Swin_UNETR/model/Swin_UNETR/Aug/Levees_SWINUNETR_48_best.pth'}\n",
            "/content/2025_levees_DL/Swin_UNETR/data/CFE_a_selected_L5_S2_S1_MSRM_PCA_GLO_N48.tif\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import monai\n",
        "from monai.inferers import sliding_window_inference\n",
        "from monai.networks.nets import SwinUNETR, AttentionUnet\n",
        "import einops\n",
        "import warnings\n",
        "import json\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import os\n",
        "import rasterio\n",
        "from rasterio.windows import Window\n",
        "import tifffile as tiff\n",
        "\n",
        "\n",
        "def get_filename_without_extension():\n",
        "    data_to_detect = image_path\n",
        "    filename_to_detect = os.path.splitext(os.path.basename(data_to_detect))[0]\n",
        "    return filename_to_detect\n",
        "filename_to_detect = get_filename_without_extension()\n",
        "\n",
        "class NumpyDataset(Dataset):\n",
        "    def __init__(self, image_paths, label_data):\n",
        "        self.image_paths = image_paths\n",
        "        self.label_data = label_data  # Accept either paths or preloaded arrays\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = np.load(self.image_paths[idx])\n",
        "\n",
        "        # Check if label_data contains paths or arrays\n",
        "        if isinstance(self.label_data[idx], str):\n",
        "            label = np.load(self.label_data[idx])\n",
        "        else:\n",
        "            label = self.label_data[idx]\n",
        "\n",
        "        image = self.replace_nans_in_array(image)\n",
        "        label = self.replace_nans_in_array(label)\n",
        "\n",
        "        image = torch.tensor(image, dtype=torch.float32)\n",
        "        label = torch.tensor(label, dtype=torch.float32)\n",
        "\n",
        "        return image, label, self.image_paths[idx]\n",
        "\n",
        "    @staticmethod\n",
        "    def replace_nans_in_array(arr):\n",
        "        arr[np.isnan(arr)] = 0\n",
        "        arr[np.isinf(arr)] = 0\n",
        "        return arr\n",
        "\n",
        "\n",
        "def load_dataset_json(json_path):\n",
        "    with open(json_path, 'r') as file:\n",
        "        dataset_json = json.load(file)\n",
        "    return dataset_json\n",
        "\n",
        "def prepare_test_loader(test_image_paths, batch_size):\n",
        "    dummy_label_dir = \"./model/temp_labels/\"\n",
        "    if not os.path.exists(dummy_label_dir):\n",
        "        os.makedirs(dummy_label_dir)\n",
        "\n",
        "    test_labels = []\n",
        "    for image_path in test_image_paths:\n",
        "        dummy_label_path = os.path.join(dummy_label_dir, os.path.basename(image_path).replace('.npy', '_label.npy'))\n",
        "        np.save(dummy_label_path, np.zeros_like(np.load(image_path)))\n",
        "        test_labels.append(dummy_label_path)\n",
        "\n",
        "    test_dataset = NumpyDataset(test_image_paths, test_labels)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
        "\n",
        "    return test_loader\n",
        "\n",
        "def initialize_model():\n",
        "    \"\"\"Initialize the SwinUNETR model.\"\"\"\n",
        "    model = SwinUNETR(\n",
        "        img_size=(96, 96),\n",
        "        in_channels=48,\n",
        "        out_channels=1,  # Use the passed `num_classes`\n",
        "        use_checkpoint=True,\n",
        "        feature_size=48,\n",
        "        depths=(3, 9, 18, 3),\n",
        "        num_heads=(4, 8, 16, 32),\n",
        "        drop_rate=0.1,  # Added dropout\n",
        "        attn_drop_rate=0.1,\n",
        "        dropout_path_rate=0.2,\n",
        "        spatial_dims=2\n",
        "    )\n",
        "    return model\n",
        "\n",
        "\n",
        "def load_adapted_model(model, checkpoint_path):\n",
        "    checkpoint = torch.load(checkpoint_path, map_location='cpu')\n",
        "    model.load_state_dict(checkpoint, strict=False)\n",
        "    return model\n",
        "\n",
        "### Load model\n",
        "\n",
        "def load_large_image(image_path):\n",
        "    print(f\"Loading large image from {image_path}\")\n",
        "    with rasterio.open(image_path) as src:\n",
        "        image = src.read()\n",
        "        transform = src.transform  # Capture the affine transformation matrix\n",
        "    return image, transform\n",
        "\n",
        "def split_to_tiles(image, tile_size, save_dir):\n",
        "    print(f\"Splitting image into tiles of size {tile_size}x{tile_size}\")\n",
        "    tiles = []\n",
        "    num_channels, height, width = image.shape\n",
        "    for i in range(0, height, tile_size):\n",
        "        for j in range(0, width, tile_size):\n",
        "            window = Window(j, i, tile_size, tile_size)\n",
        "            tile = image[:, i:i+tile_size, j:j+tile_size]\n",
        "            if tile.shape[1] == tile_size and tile.shape[2] == tile_size:\n",
        "                tile_path = os.path.join(save_dir, f'tile_{i}_{j}.tif')\n",
        "                print(f\"Saving tile to {tile_path}\")\n",
        "                tiff.imwrite(tile_path, tile)\n",
        "                tiles.append(tile_path)\n",
        "    print(f\"Total number of tiles: {len(tiles)}\")\n",
        "    return tiles\n",
        "\n",
        "def convert_tiles_to_npy(tile_paths, npy_dir):\n",
        "    if not os.path.exists(npy_dir):\n",
        "        os.makedirs(npy_dir)\n",
        "    npy_paths = []\n",
        "    for tile_path in tile_paths:\n",
        "        image = tiff.imread(tile_path)\n",
        "        npy_path = os.path.join(npy_dir, os.path.basename(tile_path).replace('.tif', '.npy'))\n",
        "        print(f\"Converting {tile_path} to {npy_path}\")\n",
        "        np.save(npy_path, image)\n",
        "        npy_paths.append(npy_path)\n",
        "    return npy_paths\n",
        "\n",
        "def merge_tiles(tiles, image_shape, tile_size):\n",
        "    print(f\"Merging tiles back into full image of shape {image_shape}\")\n",
        "    _, height, width = image_shape  # Assume image_shape is in the format (num_channels, height, width)\n",
        "    full_image = np.zeros((height, width), dtype=np.uint8)  # Only one channel for the full image\n",
        "\n",
        "    for tile_path in tiles:\n",
        "        tile = tiff.imread(tile_path)\n",
        "        # Adjust the parsing to match the filename pattern used in split_to_tiles\n",
        "        filename = os.path.basename(tile_path)\n",
        "        parts = filename.replace('tile_', '').replace('.tif', '').split('_')\n",
        "        if len(parts) == 2:  # Ensure the filename format is correct\n",
        "            i, j = map(int, parts)\n",
        "            full_image[i:i+tile_size, j:j+tile_size] = tile  # Single channel tile assignment\n",
        "        else:\n",
        "            print(f\"Unexpected filename format: {filename}\")\n",
        "\n",
        "    return full_image\n",
        "###\n",
        "\n",
        "def predict_and_save(model, test_loader, device, tile_paths, save_dir='model/temp_pred'):\n",
        "    if not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "\n",
        "    print(f\"Starting prediction on device: {device}\")\n",
        "    model.eval()\n",
        "    model.to(device)\n",
        "    predictions = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, batch in enumerate(test_loader):\n",
        "            images, _, _ = batch  # Unpack the batch; labels and paths are not needed for predictions\n",
        "            print(f\"Predicting batch {batch_idx + 1}/{len(test_loader)}\")\n",
        "            print(f\"Images type: {type(images)}, Images shape: {images.shape if isinstance(images, torch.Tensor) else 'unknown'}\")\n",
        "\n",
        "            images = images.to(device)  # Move images to the correct device\n",
        "            outputs = model(images)\n",
        "            outputs = torch.sigmoid(outputs)\n",
        "            outputs = outputs.cpu().numpy()\n",
        "\n",
        "            # Save the predictions for each image in the batch\n",
        "            for i in range(images.shape[0]):\n",
        "                output_image = outputs[i]\n",
        "                binary_output = (output_image > 0.5).astype(np.uint8)  # Apply threshold to create binary output\n",
        "                original_tile_name = os.path.basename(tile_paths[batch_idx * test_loader.batch_size + i]).replace('.npy', '.tif')\n",
        "                save_path = os.path.join(save_dir, original_tile_name)\n",
        "                print(f\"Saving prediction to {save_path}\")\n",
        "                tiff.imwrite(save_path, binary_output)\n",
        "                predictions.append(save_path)\n",
        "\n",
        "    return predictions\n",
        "\n",
        "\n",
        "\n",
        "def save_full_raster(predictions, image_shape, tile_size, save_path):\n",
        "    print(f\"Saving full raster to {save_path}\")\n",
        "    full_raster = merge_tiles(predictions, image_shape, tile_size)\n",
        "    with rasterio.open(save_path, 'w', driver='GTiff', height=full_raster.shape[0],\n",
        "                       width=full_raster.shape[1], count=1, dtype=full_raster.dtype) as dst:\n",
        "        dst.write(full_raster, 1)\n",
        "\n",
        "def create_tfw_file(transform, tfw_path):\n",
        "    print(f\"Creating .tfw file at {tfw_path}\")\n",
        "    with open(tfw_path, 'w') as f:\n",
        "        f.write(f\"{transform.a}\\n\")  # pixel size in the x-direction\n",
        "        f.write(f\"{transform.b}\\n\")  # rotation term (always 0 for north-up images)\n",
        "        f.write(f\"{transform.d}\\n\")  # rotation term (always 0 for north-up images)\n",
        "        f.write(f\"{transform.e}\\n\")  # pixel size in the y-direction (usually negative)\n",
        "        f.write(f\"{transform.c}\\n\")  # x-coordinate of the upper-left corner of the upper-left pixel\n",
        "        f.write(f\"{transform.f}\\n\")  # y-coordinate of the upper-left corner of the upper-left pixel\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    image_path = data_path\n",
        "\n",
        "    tile_size = 96\n",
        "    batch_size = 12\n",
        "    model = initialize_model()\n",
        "\n",
        "    print(\"Loading and preprocessing the large image\")\n",
        "    large_image, transform = load_large_image(image_path)\n",
        "    large_image = NumpyDataset.replace_nans_in_array(large_image)\n",
        "    image_shape = large_image.shape\n",
        "    print(f\"Large image shape: {image_shape}\")\n",
        "\n",
        "    temp_dir = f'{Swin_UNETR_path}/results/temp/'\n",
        "    npy_dir = f'{Swin_UNETR_path}/results/temp_npy/'\n",
        "    pred_dir = f'{Swin_UNETR_path}/results/temp_pred/'\n",
        "    result_path = f'{Swin_UNETR_path}/results/Swin_UNETR/Aug/{filename_to_detect}_swinunetr.tif'\n",
        "    tfw_path = f'{Swin_UNETR_path}/results/Swin_UNETR/Aug/{filename_to_detect}_swinunetr.tfw'\n",
        "\n",
        "    if not os.path.exists(temp_dir):\n",
        "        os.makedirs(temp_dir)\n",
        "\n",
        "    tile_paths = split_to_tiles(large_image, tile_size, temp_dir)\n",
        "    npy_paths = convert_tiles_to_npy(tile_paths, npy_dir)\n",
        "    test_loader = prepare_test_loader(npy_paths, batch_size)\n",
        "\n",
        "    adapted_model_path = Swin_UNETR_pth\n",
        "    model = load_adapted_model(model, adapted_model_path)\n",
        "\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    predictions = predict_and_save(model, test_loader, device, tile_paths, save_dir=pred_dir)\n",
        "\n",
        "    # Adjust the image_shape to reflect the single-channel output\n",
        "    single_channel_image_shape = (1, image_shape[1], image_shape[2])\n",
        "    save_full_raster(predictions, single_channel_image_shape, tile_size, result_path)\n",
        "\n",
        "    # Create the .tfw file using the transform from the original large image\n",
        "    create_tfw_file(transform, tfw_path)\n",
        "\n",
        "    print(\"Prediction, saving, and .tfw file creation complete\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "FZLbW3Wp398r",
        "outputId": "4773cec1-1e5a-4f8b-812e-aab64c01b85f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'image_path' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3988149494.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mfilename_to_detect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_detect\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfilename_to_detect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mfilename_to_detect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_filename_without_extension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mNumpyDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3988149494.py\u001b[0m in \u001b[0;36mget_filename_without_extension\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_filename_without_extension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mdata_to_detect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mfilename_to_detect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_detect\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfilename_to_detect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'image_path' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import rasterio\n",
        "from skimage import io\n",
        "from skimage.morphology import thin\n",
        "from scipy.ndimage import distance_transform_edt\n",
        "from skimage.morphology import skeletonize\n",
        "\n",
        "# ====== INPUT data ======\n",
        "# raster_r = input(\"Enter path to raster data: \").strip('\"') # change to process other files\n",
        "raster_r = result_path\n",
        "def get_filename_without_extension():\n",
        "    return os.path.splitext(os.path.basename(raster_r))[0]\n",
        "filename_to_detect = get_filename_without_extension()\n",
        "def load_large_image(image_path):\n",
        "    print(f\"Loading large image from {image_path}\")\n",
        "    with rasterio.open(image_path) as src:\n",
        "        image = src.read(1)  # Read first band\n",
        "        transform = src.transform\n",
        "    return image, transform\n",
        "\n",
        "binary_raster, transform = load_large_image(raster_r)\n",
        "binary_raster = (binary_raster > 0).astype(np.uint8)  # Ensure binary\n",
        "\n",
        "# REMOVE SMALL OBJECTS\n",
        "min_area = 350\n",
        "num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(binary_raster, connectivity=8)\n",
        "\n",
        "# Keep only features above the selected min_area parameter\n",
        "filtered_raster = np.zeros_like(binary_raster, dtype=np.uint8)\n",
        "for i in range(1, num_labels):  # skip background\n",
        "    if stats[i, cv2.CC_STAT_AREA] >= min_area:\n",
        "        filtered_raster[labels == i] = 1\n",
        "\n",
        "# Save TFW file to preserve geographic location\n",
        "def create_tfw_file(transform, tfw_path):\n",
        "    print(f\"Creating .tfw file at {tfw_path}\")\n",
        "    with open(tfw_path, 'w') as f:\n",
        "        f.write(f\"{transform.a}\\n\")\n",
        "        f.write(f\"{transform.b}\\n\")\n",
        "        f.write(f\"{transform.d}\\n\")\n",
        "        f.write(f\"{transform.e}\\n\")\n",
        "        f.write(f\"{transform.c}\\n\")\n",
        "        f.write(f\"{transform.f}\\n\")\n",
        "\n",
        "# Output\n",
        "output_dir = results_path\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "filtered_dir = os.path.join(output_dir, \"Filtered\")\n",
        "os.makedirs(filtered_dir, exist_ok=True)\n",
        "\n",
        "# Save\n",
        "filtered_tif_path = os.path.join(filtered_dir, f'{filename_to_detect}_filtered.tif')\n",
        "io.imsave(filtered_tif_path, (filtered_raster * 1).astype(np.uint8))\n",
        "create_tfw_file(transform, os.path.splitext(filtered_tif_path)[0] + '.tfw')\n",
        "\n",
        "print(\"Filtering complete. Small features removed and .tfw file saved.\")\n",
        "\n",
        "# CLOSING\n",
        "kernel = np.ones((7,7),np.uint8)\n",
        "closing_raster = cv2.morphologyEx(filtered_raster, cv2.MORPH_CLOSE, kernel)\n",
        "\n",
        "# SAVE CLOSING results\n",
        "closing_tif_path = os.path.join(filtered_dir, f'{filename_to_detect}_closing.tif')\n",
        "cv2.imwrite(closing_tif_path, (closing_raster * 1).astype(np.uint8))\n",
        "create_tfw_file(transform, os.path.splitext(closing_tif_path)[0] + '.tfw')\n",
        "\n",
        "\n",
        "# Skeletonize\n",
        "skeletonize_raster = skeletonize(closing_raster > 0, method='lee')\n",
        "skeletonize_raster = (skeletonize_raster * 1).astype(np.uint8)\n",
        "\n",
        "# Save the final results\n",
        "skeletonize_raster_tif_path = os.path.join(output_dir, f'{filename_to_detect}_skeletonize.tif')\n",
        "cv2.imwrite(skeletonize_raster_tif_path, skeletonize_raster)\n",
        "create_tfw_file(transform, os.path.splitext(skeletonize_raster_tif_path)[0] + '.tfw')\n"
      ],
      "metadata": {
        "id": "qJeE6DuZLyfp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "# MEGA file URL\n",
        "mega_url2 = \"https://mega.nz/file/5txRRQiZ#dDRqdI4F695r7yG465W5KIISVdQ1Iw2O8EWK2BIdoFs\"\n",
        "\n",
        "# Temporary download path (megadl saves the file with original name by default)\n",
        "download_dir3 = \"/content\"\n",
        "downloaded_file = os.path.join(download_dir, \"CFE_a_levee_reference.tif\")\n",
        "\n",
        "# Target directory\n",
        "target_dir3 = f'{Swin_UNETR_path}/data'\n",
        "os.makedirs(target_dir3, exist_ok=True)\n",
        "\n",
        "# Download file using megadl\n",
        "!megadl \"{mega_url2}\" --path \"{download_dir3}\"\n",
        "\n",
        "# Move the file to target directory (if needed rename)\n",
        "shutil.move(downloaded_file, os.path.join(target_dir3, \"CFE_a_levee_reference.tif\"))\n",
        "print(f\"File moved to: {target_dir3}\")\n",
        "\n",
        "Reference_data_path = os.path.join(target_dir3, \"CFE_a_levee_reference.tif\")\n"
      ],
      "metadata": {
        "id": "O3sTFjjbjIL3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uYjlQIW0rj2m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import rasterio\n",
        "from rasterio.enums import Resampling\n",
        "from rasterio.warp import reproject\n",
        "from rasterio.transform import Affine\n",
        "from scipy.ndimage import binary_dilation, binary_erosion\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Step 1. Read spatial coordinates from TFW\n",
        "# ------------------------------------------------------------\n",
        "def read_tfw_coordinates(tif_path):\n",
        "    tfw_path = os.path.splitext(tif_path)[0] + \".tfw\"\n",
        "    if not os.path.exists(tfw_path):\n",
        "        raise FileNotFoundError(f\"World file not found: {tfw_path}\")\n",
        "\n",
        "    with open(tfw_path, \"r\") as f:\n",
        "        lines = f.readlines()\n",
        "    if len(lines) != 6:\n",
        "        raise ValueError(f\"Invalid world file format: {tfw_path}\")\n",
        "\n",
        "    # Parse six parameters\n",
        "    A = float(lines[0])  # pixel size in X\n",
        "    D = float(lines[1])  # rotation term\n",
        "    B = float(lines[2])  # rotation term\n",
        "    E = float(lines[3])  # pixel size in Y\n",
        "    C = float(lines[4])  # X coordinate of center of upper-left pixel\n",
        "    F = float(lines[5])  # Y coordinate of center of upper-left pixel\n",
        "\n",
        "    transform = Affine(A, B, C, D, E, F)\n",
        "    print(\"\\n[TFW] Affine transform read from file:\")\n",
        "\n",
        "    return transform\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Step 2. Align reference raster to predicted raster\n",
        "# ------------------------------------------------------------\n",
        "\n",
        "def align_reference_with_crs(reference_tif, predicted_tif, predicted_transform, dst_crs, output_path):\n",
        "    with rasterio.open(predicted_tif) as pred:\n",
        "        dst_width = pred.width\n",
        "        dst_height = pred.height\n",
        "        dst_profile = pred.profile.copy()\n",
        "\n",
        "    with rasterio.open(reference_tif) as ref:\n",
        "        if ref.crs is None:\n",
        "            raise ValueError(\"Reference raster has no CRS — cannot reproject.\")\n",
        "        src_dtype = ref.dtypes[0]\n",
        "        dest = np.zeros((dst_height, dst_width), dtype=src_dtype)\n",
        "\n",
        "        reproject(\n",
        "            source=rasterio.band(ref, 1),\n",
        "            destination=dest,\n",
        "            src_transform=ref.transform,\n",
        "            src_crs=ref.crs,\n",
        "            dst_transform=predicted_transform,\n",
        "            dst_crs=dst_crs,\n",
        "            resampling=Resampling.nearest,\n",
        "            num_threads=2\n",
        "        )\n",
        "\n",
        "    dst_profile.update(\n",
        "        dtype=src_dtype,\n",
        "        count=1,\n",
        "        compress=\"lzw\",\n",
        "        driver=\"GTiff\",\n",
        "        transform=predicted_transform,\n",
        "        crs=dst_crs,\n",
        "        width=dst_width,\n",
        "        height=dst_height\n",
        "    )\n",
        "\n",
        "    with rasterio.open(output_path, \"w\", **dst_profile) as dst:\n",
        "        dst.write(dest, 1)\n",
        "\n",
        "    print(f\"\\nAligned reference raster saved to:\\n{output_path}\")\n",
        "    return output_path\n",
        "\n",
        "\n",
        "\n",
        "def align_reference(reference_tif, predicted_tif, predicted_transform, output_path):\n",
        "    with rasterio.open(predicted_tif) as pred:\n",
        "        dst_crs = pred.crs\n",
        "        dst_width = pred.width\n",
        "        dst_height = pred.height\n",
        "        dst_profile = pred.profile.copy()\n",
        "\n",
        "    with rasterio.open(reference_tif) as ref:\n",
        "        if ref.crs is None:\n",
        "            raise ValueError(\"Reference raster has no CRS — cannot reproject.\")\n",
        "        src_dtype = ref.dtypes[0]\n",
        "        dest = np.zeros((dst_height, dst_width), dtype=src_dtype)\n",
        "\n",
        "        reproject(\n",
        "            source=rasterio.band(ref, 1),\n",
        "            destination=dest,\n",
        "            src_transform=ref.transform,\n",
        "            src_crs=ref.crs,\n",
        "            dst_transform=predicted_transform,\n",
        "            dst_crs=dst_crs,\n",
        "            resampling=Resampling.nearest,\n",
        "            num_threads=2\n",
        "        )\n",
        "\n",
        "    dst_profile.update(\n",
        "        dtype=src_dtype,\n",
        "        count=1,\n",
        "        compress=\"lzw\",\n",
        "        driver=\"GTiff\",\n",
        "        transform=predicted_transform,\n",
        "        crs=dst_crs,\n",
        "        width=dst_width,\n",
        "        height=dst_height\n",
        "    )\n",
        "\n",
        "    with rasterio.open(output_path, \"w\", **dst_profile) as dst:\n",
        "        dst.write(dest, 1)\n",
        "\n",
        "    print(f\"\\nAligned reference raster saved to:\\n{output_path}\")\n",
        "    return output_path\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Step 3. Compare rasters\n",
        "# ------------------------------------------------------------\n",
        "def compare_rasters(reference_tif, predicted_tif, IoU_buf):\n",
        "    with rasterio.open(reference_tif) as ref_src:\n",
        "        ref_data = ref_src.read(1)\n",
        "        profile = ref_src.profile\n",
        "\n",
        "    with rasterio.open(predicted_tif) as pred_src:\n",
        "        pred_data = pred_src.read(1)\n",
        "\n",
        "    if ref_data.shape != pred_data.shape:\n",
        "        raise ValueError(\"Rasters must have the same dimensions and alignment.\")\n",
        "\n",
        "    struct_element = np.ones((IoU_buf, IoU_buf))\n",
        "    buffered_ref = binary_dilation(ref_data, structure=struct_element).astype(ref_data.dtype)\n",
        "    eroded_pred_data = binary_erosion(pred_data, structure=struct_element).astype(pred_data.dtype)\n",
        "\n",
        "    TP = (buffered_ref == 1) & (eroded_pred_data == 1)\n",
        "    FP = (buffered_ref == 0) & (eroded_pred_data == 1)\n",
        "    FN = (buffered_ref == 1) & (eroded_pred_data == 0)\n",
        "\n",
        "    output_data = np.zeros_like(eroded_pred_data, dtype=np.int8)\n",
        "    output_data[TP] = 1\n",
        "    output_data[FP] = -1\n",
        "    output_data[FN] = 2\n",
        "\n",
        "    tp_count = np.sum(TP)\n",
        "    fp_count = np.sum(FP)\n",
        "    fn_count = np.sum(FN)\n",
        "\n",
        "    precision = tp_count / (tp_count + fp_count) if (tp_count + fp_count) > 0 else 0\n",
        "    recall = tp_count / (tp_count + fn_count) if (tp_count + fn_count) > 0 else 0\n",
        "    f1_score = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "    iou = tp_count / (tp_count + fp_count + fn_count) if (tp_count + fp_count + fn_count) > 0 else 0\n",
        "\n",
        "    print(f\"\\n--- Evaluation Metrics ---\")\n",
        "    print(f\"IoU:        {iou:.4f}\")\n",
        "    print(f\"Precision:  {precision:.4f}\")\n",
        "    print(f\"Recall:     {recall:.4f}\")\n",
        "    print(f\"F1 Score:   {f1_score:.4f}\")\n",
        "\n",
        "    output_path = predicted_tif.replace(\".tif\", f\"_comparison_buf{IoU_buf}.tif\")\n",
        "    profile.update(dtype=rasterio.int8, count=1)\n",
        "\n",
        "    with rasterio.open(output_path, \"w\", **profile) as dst:\n",
        "        dst.write(output_data, 1)\n",
        "\n",
        "    print(f\"Comparison raster saved to:\\n{output_path}\")\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Step 4. Main workflow\n",
        "# ------------------------------------------------------------\n",
        "def main():\n",
        "    reference_tif_ = Reference_data_path\n",
        "    #reference_tif = input(\"Enter path to reference data: \").strip('\"') # If manual selection is needed\n",
        "    predicted_tif = closing_tif_path\n",
        "    #predicted_tif = input(\"Enter path to predicted data: \").strip('\"') # If manual selection is needed\n",
        "\n",
        "    IoU_buf = 1  # buffer size for dilation/erosion\n",
        "\n",
        "    # Step 1: Read transform from TFW file\n",
        "    predicted_transform = read_tfw_coordinates(predicted_tif)\n",
        "\n",
        "    # Step 1b: Define CRS manually (replace EPSG code as needed!)\n",
        "    from rasterio.crs import CRS\n",
        "    dst_crs = CRS.from_epsg(4326)   #\n",
        "\n",
        "    # Step 2: Align reference raster\n",
        "    aligned_ref_path = os.path.splitext(predicted_tif)[0] + \"_ref_aligned.tif\"\n",
        "    aligned_ref = align_reference_with_crs(reference_tif, predicted_tif, predicted_transform, dst_crs, aligned_ref_path)\n",
        "\n",
        "    # Step 3: Compare rasters\n",
        "    compare_rasters(aligned_ref, predicted_tif, IoU_buf)\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "G-Pf_EPvnrLM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}